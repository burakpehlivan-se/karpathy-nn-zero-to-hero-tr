# ğŸ§  Neural Networks: Zero to Hero (TÃ¼rkÃ§e AÃ§Ä±klamalÄ±)

Bu depo, Andrej Karpathy'nin efsanevi **"Neural Networks: Zero to Hero"** video serisi iÃ§in hazÄ±rladÄ±ÄŸÄ±m detaylÄ± TÃ¼rkÃ§e notlarÄ±, kod aÃ§Ä±klamalarÄ±nÄ± ve yeniden oluÅŸturulmuÅŸ implementasyonlarÄ± iÃ§erir.

AmacÄ±m, "Micrograd" ile baÅŸlayÄ±p "GPT-2" ve "Reasoning Models"e kadar uzanan bu yolculuÄŸu, TÃ¼rkÃ§e kaynak arayanlar iÃ§in anlaÅŸÄ±lÄ±r, kapsamlÄ± ve eÄŸitici bir rehber haline getirmektir.

## ğŸš€ Ä°Ã§erik ve Ä°lerleme Durumu

Bu proje, orijinal oynatma listesindeki sÄ±rayÄ± takip etmektedir.

| BÃ¶lÃ¼m | Konu | Orijinal Ders | TÃ¼rkÃ§e Notlar | Durum |
| :--- | :--- | :---: | :---: | :---: |
| **01** | **Micrograd:** Autograd Motoru ve Backpropagation | [Video](https://youtu.be/VMj-3S1tku0?si=5rrYqRZgOwv05eNt) | [Ä°ncele](./01_micrograd/) | âœ… TamamlandÄ± |
| **02** | **Makemore 1:** Bigram (Ä°kili) Dil Modelleri | [Video](https://youtu.be/PaCmpygFfXo?si=u4T45UwGYyv1POIo) | - | â³ Bekleniyor |
| **03** | **Makemore 2:** MLP (Multi-Layer Perceptron) | [Video](https://youtu.be/TCH_1BHY58I?si=7rmvaSXQgIg3rBUj) | - | â³ Bekleniyor |
| **04** | **Makemore 3:** Batch Normalization & Internals | [Video](https://youtu.be/P6sfmUTpUmc?si=4e1Qp0iHsl90Mhay) | - | â³ Bekleniyor |
| **05** | **Makemore 4:** Backpropagation Ninja (Manuel TÃ¼rev) | [Video](https://youtu.be/q8SA3rM6ckI?si=baT6jXkJpbyFTmYf) | - | â³ Bekleniyor |
| **06** | **Makemore 5:** WaveNet Mimarisi & CNN'ler | [Video](https://youtu.be/t3YJ5hKiMQ0?si=2mO9hxINaK3slCbG) | - | â³ Bekleniyor |
| **07** | **GPT:** SÄ±fÄ±rdan GPT OluÅŸturmak ve Transformer Mimarisi (Attention is all you need) | [Video](https://youtu.be/kCc8FmEb1nY?si=4uU7c16tJMximB_8) | - | â³ Bekleniyor |
| **08** | **GPT EÄŸitim AÅŸamalarÄ±:** BÃ¼yÃ¼k Dil Modellerine GiriÅŸ (Teori) | [video](https://youtu.be/bZQun8Y4L2A?si=U5FYZfC43uwAESbG) | - | â³ Bekleniyor |
| **09** | **Tokenizer:** GPT Tokenizer (KodlayÄ±cÄ±) OluÅŸturma | [Video](https://youtu.be/bZQun8Y4L2A?si=jf-k9GKnhfmfDaMM) | - | â³ Bekleniyor |
| **10** | **GPT-2:** GPT-2 (124M) Modelini SÄ±fÄ±rdan EÄŸitmek | [Video](https://youtu.be/l8pRSuU81PU) | - | â³ Bekleniyor |

---

## ğŸ“‚ Proje YapÄ±sÄ±

Her bÃ¶lÃ¼m, kendi klasÃ¶rÃ¼ altÄ±nda organize edilmiÅŸtir. Bu klasÃ¶rlerde Jupyter Notebook (`.ipynb`) dosyalarÄ±, ilgili veri setleri ve aÃ§Ä±klamalar bulunur.

```text
karpathy-nn-zero-to-hero-tr/
â”œâ”€â”€ 01_micrograd/          # Geriye yayÄ±lÄ±m ve tÃ¼rev motoru
â”œâ”€â”€ 02_makemore_bigram/    # Ä°statistiksel dil modellemesi
â”œâ”€â”€ ...
â”œâ”€â”€ 09_gpt2_reproduction/  # BÃ¼yÃ¼k Ã¶lÃ§ekli model eÄŸitimi
â””â”€â”€ requirements.txt       # Gerekli kÃ¼tÃ¼phaneler

```

## ğŸ› ï¸ Kurulum ve KullanÄ±m

NotlarÄ± kendi bilgisayarÄ±nÄ±zda Ã§alÄ±ÅŸtÄ±rmak iÃ§in aÅŸaÄŸÄ±daki adÄ±mlarÄ± izleyebilirsiniz.

1. **Repoyu KlonlayÄ±n:**
```bash
git clone [https://github.com/KULLANICI_ADIN/REPO_ADIN.git](https://github.com/KULLANICI_ADIN/REPO_ADIN.git)
cd REPO_ADIN

```


2. **Gerekli KÃ¼tÃ¼phaneleri YÃ¼kleyin:**
Proje genelinde `pytorch`, `numpy`, `matplotlib`, `graphviz` ve `jupyter` kullanÄ±lmaktadÄ±r.
```bash
pip install -r requirements.txt

```


*(Not: `graphviz` iÃ§in sisteminize ekstra binary kurulumu yapmanÄ±z gerekebilir.)*
3. **Notebook'u BaÅŸlatÄ±n:**
```bash
jupyter notebook

```



## ğŸ“š KaynakÃ§a ve AtÄ±f

Bu Ã§alÄ±ÅŸma tamamen **Andrej Karpathy**'nin eÄŸitim serisine dayanmaktadÄ±r. Orijinal materyallere ve Karpathy'nin kendi repolarÄ±na aÅŸaÄŸÄ±daki linklerden ulaÅŸabilirsiniz:

* **YouTube Playlist:** [Neural Networks: Zero to Hero](https://www.youtube.com/playlist?list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ)
* **Micrograd Repo:** [github.com/karpathy/micrograd](https://github.com/karpathy/micrograd)
* **Makemore Repo:** [github.com/karpathy/makemore](https://github.com/karpathy/makemore)
* **NanoGPT Repo:** [github.com/karpathy/nanoGPT](https://github.com/karpathy/nanoGPT)
* **LLM.c Repo:** [github.com/karpathy/llm.c](https://github.com/karpathy/llm.c)

## ğŸ¤ KatkÄ±da Bulunma

EÄŸer notlarda bir hata fark ederseniz veya TÃ¼rkÃ§e Ã§evirilerde dÃ¼zeltme yapmak isterseniz, lÃ¼tfen bir **Issue** aÃ§maktan veya **Pull Request** gÃ¶ndermekten Ã§ekinmeyin.

---

*HazÄ±rlayan: [Senin AdÄ±n]*

```

```
